{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1SP7bPYpX2R640lgK36R63vE3kPGAOAnT",
      "authorship_tag": "ABX9TyOyo/R1jBdTm4XarSNuJcE9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reichidad/Machine-Learning-2020-Spring-Class/blob/assignment09/assignment09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hClwdP_V-zE5",
        "colab_type": "text"
      },
      "source": [
        "# Multi-label classification using neural networks\n",
        "## 20145822 김영현\n",
        "___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdYLaCI1_E-d",
        "colab_type": "text"
      },
      "source": [
        "## Training & Testing Code\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uutii1Se-pjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "file_data   = \"/content/drive/My Drive/Colab Notebooks/data09/mnist.csv\"\n",
        "handle_file = open(file_data, \"r\")\n",
        "data        = handle_file.readlines()\n",
        "handle_file.close()\n",
        "\n",
        "size_row    = 28    # height of the image\n",
        "size_col    = 28    # width of the image\n",
        "\n",
        "num_image   = len(data)\n",
        "num_train = 6000\n",
        "num_test = 4000\n",
        "count       = 0     # count for the number of images\n",
        "\n",
        "#\n",
        "# normalize the values of the input data to be [0, 1]\n",
        "#\n",
        "def normalize(data):\n",
        "\n",
        "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
        "\n",
        "    return(data_normalized)\n",
        "\n",
        "#\n",
        "# make a matrix each column of which represents an images in a vector form\n",
        "#\n",
        "list_image_train  = np.empty((size_row * size_col, num_train), dtype=float)\n",
        "list_label_train  = np.empty(num_train, dtype=int)\n",
        "list_image_test = np.empty((size_row * size_col, num_train), dtype=float)\n",
        "list_label_test  = np.empty(num_test, dtype=int)\n",
        "\n",
        "train_loss_list = []\n",
        "train_accr_list = []\n",
        "test_loss_list = []\n",
        "test_accr_list = []\n",
        "\n",
        "for line in data:\n",
        "\n",
        "    line_data   = line.split(',')\n",
        "    label       = line_data[0]\n",
        "    im_vector   = np.asfarray(line_data[1:])\n",
        "    im_vector   = normalize(im_vector)\n",
        "\n",
        "    if count < num_train:\n",
        "      list_label_train[count]       = label\n",
        "      list_image_train[:, count]    = im_vector\n",
        "    else:\n",
        "      list_label_test[count - num_train] = label\n",
        "      list_image_test[:, count - num_train] = im_vector\n",
        "    count += 1\n",
        "\n",
        "theta_u = np.random.randn(196, 785)\n",
        "theta_v = np.random.randn(49, 197)\n",
        "theta_w = np.random.randn(10,50)\n",
        "alpha = 0.9\n",
        "\n",
        "one_hot_label_train = np.zeros((10, num_train), dtype=float)\n",
        "for i in range(num_train):\n",
        "  one_hot_label_train[list_label_train[i],i] = 1\n",
        "one_hot_label_test = np.zeros((10, num_test), dtype=float)\n",
        "for i in range(num_test):\n",
        "  one_hot_label_test[list_label_test[i],i] = 1\n",
        "# fully connected calculation with bias(1)\n",
        "def func_calc(theta_list, op_list):\n",
        "  return np.matmul(theta_list, np.insert(op_list, 0, 1))\n",
        "\n",
        "\n",
        "# sigmoid calculation\n",
        "def sigmoid(val):\n",
        "  return 1/(1+np.exp(-val))\n",
        "\n",
        "\n",
        "# derivative of the sigmoid\n",
        "def d_sigmoid(val):\n",
        "  sig_now = sigmoid(val)\n",
        "  return sig_now * (1 - sig_now)\n",
        "\n",
        "\n",
        "# objective function\n",
        "def ob_func(labels, results, num):\n",
        "  sum = 0\n",
        "  for i in range(num):\n",
        "    for j in range(len(results)):\n",
        "      sum += (-labels[j,i] * np.log(results[j][i])) - ((1 - labels[j,i]) * np.log(1 - results[j][i]))\n",
        "  return sum/num\n",
        "\n",
        "\n",
        "# main function for 1 iteration\n",
        "def train_once():\n",
        "  global theta_u, theta_v, theta_w\n",
        "  result_set = np.empty((10, num_train))\n",
        "  accr = 0\n",
        "  theta_u_next = np.zeros((196, 785))\n",
        "  theta_v_next = np.zeros((49, 197))\n",
        "  theta_w_next = np.zeros((10, 50))\n",
        "  \n",
        "  for num in range(num_train):\n",
        "    x = list_image_train[:, num]\n",
        "    y = func_calc(theta_u, x)\n",
        "    y_sigmoid = sigmoid(y)\n",
        "    z= func_calc(theta_v, y_sigmoid)\n",
        "    z_sigmoid = sigmoid(z)\n",
        "    h = func_calc(theta_w, z_sigmoid)\n",
        "    h_sigmoid = sigmoid(h)\n",
        "    result_set[:, num] = h_sigmoid\n",
        "\n",
        "    if np.argmax(h_sigmoid) == list_label_train[num]:\n",
        "      accr += 1\n",
        "\n",
        "    d_first = np.zeros(10)\n",
        "    for i in range(10):\n",
        "      d_first[i] = (1-one_hot_label_train[i,num])/(1-h_sigmoid[i]) - one_hot_label_train[i,num]/h_sigmoid[i]\n",
        "      d_first[i] *= d_sigmoid(h[i])\n",
        "    theta_w_next += np.matmul(d_first.reshape(10,1), np.insert(z_sigmoid, 0, 1).reshape(1,50))\n",
        "    \n",
        "    d_second = np.matmul(d_first, theta_w)\n",
        "    for i in range(1,50):\n",
        "      d_second[i] *= d_sigmoid(z[i-1])\n",
        "    theta_v_next += np.matmul(d_second[1:].reshape(49, 1), np.insert(y_sigmoid, 0, 1).reshape(1, 197))\n",
        "\n",
        "    d_third = np.matmul(d_second[1:50], theta_v)\n",
        "    for i in range(1,197):\n",
        "      d_third[i] *= d_sigmoid(y[i-1])\n",
        "    theta_u_next += np.matmul(d_third[1:].reshape(196,1), np.insert(x, 0, 1).reshape(1, 785))\n",
        "\n",
        "  train_loss = ob_func(one_hot_label_train, result_set, num_train)\n",
        "  train_loss_list.append(train_loss)\n",
        "  accr = accr * 100 / num_train\n",
        "  train_accr_list.append(accr)\n",
        "\n",
        "  test_result_set = np.empty((10, num_train))\n",
        "  test_accr = 0\n",
        "  for num in range(num_test):\n",
        "      x = list_image_test[:, num]\n",
        "      y = func_calc(theta_u, x)\n",
        "      y_sigmoid = sigmoid(y)\n",
        "      z= func_calc(theta_v, y_sigmoid)\n",
        "      z_sigmoid = sigmoid(z)\n",
        "      h = func_calc(theta_w, z_sigmoid)\n",
        "      h_sigmoid = sigmoid(h)\n",
        "      test_result_set[:, num] = h_sigmoid\n",
        "\n",
        "      if np.argmax(h_sigmoid) == list_label_test[num]:\n",
        "        test_accr += 1\n",
        "  test_loss = ob_func(one_hot_label_test, test_result_set, num_test)\n",
        "  test_loss_list.append(test_loss)\n",
        "  test_accr = test_accr * 100 / num_test\n",
        "  test_accr_list.append(test_accr)\n",
        "\n",
        "  theta_u -= (alpha * theta_u_next/num_train)\n",
        "  theta_v -= (alpha * theta_v_next/num_train)\n",
        "  theta_w -= (alpha * theta_w_next/num_train)\n",
        "\n",
        "\n",
        "iteration = 0\n",
        "while iteration < 500:\n",
        "  train_once()\n",
        "  if iteration > 0:\n",
        "    if abs(train_loss_list[iteration] - train_loss_list[iteration-1]) < 0.001:\n",
        "      break\n",
        "  iteration += 1\n",
        "  if iteration == 400:\n",
        "    alpha = 0.1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbed_OEnXuYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "77d174d8-fa88-4561-d37e-b60b72bb0edd"
      },
      "source": [
        "print(\"iteration finished with\\n\",\n",
        "            \"iteration :\", iteration-1,\"\\n\",\n",
        "            \"train_loss :\", train_loss_list[-1],\"\\n\",\n",
        "            \"train_accr :\", train_accr_list[-1], \"%\\n\",\n",
        "            \"test_loss :\", test_loss_list[-1], \"\\n\",\n",
        "            \"test_accr :\", test_accr_list[-1], \"%\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration finished with\n",
            " iteration : 343 \n",
            " train_loss : 0.6895884150794045 \n",
            " train_accr : 90.26666666666667 %\n",
            " test_loss : 0.9352388003011123 \n",
            " test_accr : 84.65 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AvmqS5rXgYR",
        "colab_type": "text"
      },
      "source": [
        "## Submission\n",
        "___"
      ]
    }
  ]
}